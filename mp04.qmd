---
title: "mp04"
---
### Task 1: Download CES Total Nonfarm Payroll 

```{r,message=FALSE,warning=FALSE}
#| code-fold: true
#| code-summary: "Show the code"

library(tidyverse)
library(httr2)
library(rvest)

# 1. Define the URL
url <- "https://data.bls.gov/pdq/SurveyOutputServlet"

# 2. Build the Request
# We use the parameters identified from the POST payload
req <- request(url) %>% 
  req_method("POST") %>% 
  req_body_form(
    series_id = "CES0000000001",  # Total Nonfarm ID
    from_year = "1979",           # Start Year
    to_year = "2025",             # End Year
    request_action = "get_data",  # Tells server to fetch data
    reformat = "true",            # Required for the year update logic
    formatting = "standard",      # Ensures HTML table output
    output_view = "data"          # Explicitly ask for data view
  )

# 3. Perform Request & Inspect
resp <- req_perform(req)

# Check status (should be 200)
print(resp)

# 4. Extract and Clean (Proceeding with the previous logic)
clean_data <- resp %>% 
  resp_body_html() %>% 
  html_element("table.regular-data") %>% 
  html_table(header = TRUE) %>% 
  # Pivot wide to long
  pivot_longer(
    cols = -Year, 
    names_to = "Month", 
    values_to = "level"
  ) %>% 
  # Clean up formatting
  mutate(
    # Combine Year and Month (e.g., "1979 Jan")
    date_str = paste(Year, Month),
    # Parse into Date object
    date = ym(date_str),
    # Remove "(P)" and commas, then convert to numeric
    level = as.numeric(str_remove_all(level, "[^0-9.]"))
  ) %>% 
  # Filter for correct date range
  filter(
    date >= "1979-01-01",
    date <= "2025-06-01"
  ) %>% 
  select(date, level) %>% 
  arrange(date) %>% 
  drop_na()

# View final result
print(head(clean_data))

```

### Task 2: Download CES Revisions Tables 

```{r,message=FALSE,warning=FALSE}
#| code-fold: true
#| code-summary: "Show the code"

library(tidyverse)
library(httr2)
library(rvest)
library(lubridate) 

# -------------------------------------------------------------------------
# Step 1: Download the Page
# -------------------------------------------------------------------------

url_revisions <- "https://www.bls.gov/web/empsit/cesnaicsrev.htm"
req <- request(url_revisions) %>% 
  req_user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")

resp <- req_perform(req)
html_content <- resp %>% resp_body_html()

# -------------------------------------------------------------------------
# Step 2: Extract, Combine, and Clean Data
# -------------------------------------------------------------------------

raw_data_list <- html_content %>% 
  html_elements("table") %>% 
  map(~ html_table(.x, header = FALSE, fill = TRUE)) 

raw_data_combined <- bind_rows(raw_data_list)

final_revisions <- raw_data_combined %>%
  
  # 1. Clean Month Column: Remove the period (.) for accurate filtering.
  mutate(
    month_name_clean = str_remove_all(X1, "[.]")
  ) %>%
  
  # 2. Filter Data Rows: Keep only rows that correspond to actual months.
  filter(month_name_clean %in% month.abb) %>%
  
  # 3. Select Columns: X3=Original (1st), X5=Final (3rd).
  select(
    month_name = month_name_clean,
    year_val   = X2,
    original   = X3, 
    final      = X5  
  ) %>%
  
  # 4. Data Conversion and Calculation
  mutate(
    date = ym(paste(year_val, month_name)),
    original = as.numeric(str_remove_all(original, "[^0-9-]")),
    final = as.numeric(str_remove_all(final, "[^0-9-]")),
    revision = final - original
  ) %>%
  
  # 5. Final Filtering, Ordering, and Duplication Removal
  filter(
    date >= "1979-01-01",
    date <= "2025-06-01"
  ) %>%
  
  select(date, original, final, revision) %>%
  arrange(date) %>%
  drop_na() %>%
  distinct() # This step ensures all duplicated rows are removed.

# -------------------------------------------------------------------------
# Step 3: Verification
# -------------------------------------------------------------------------

print(head(final_revisions, 5))
```


```{r,message=FALSE,warning=FALSE}
#| code-fold: true
#| code-summary: "Show the code"

# Load libraries
library(tidyverse)
library(lubridate)

# Assuming 'clean_data' has columns: date and level (for overall employment in thousands)

combined_data <- final_revisions %>%
  # Join the revisions data with the total employment level data
  inner_join(clean_data, by = "date") %>%
  
  # Calculate useful new variables for exploration
  mutate(
    # Absolute revision magnitude (to track size of error, regardless of direction)
    abs_revision = abs(revision), 
    
    # Absolute revision as a percentage of overall employment level
    abs_rev_pct_level = (abs_revision / level) * 100, 
    
    # Absolute revision as a percentage of the final estimate
    abs_rev_pct_estimate = (abs_revision / final) * 100,
    
    # Extract month, year, and decade for group analysis
    month = month(date, label = TRUE, abbr = TRUE),
    year = year(date),
    decade = floor(year / 10) * 10
  )

# Display the structure of the combined data to confirm the join
print(head(combined_data))

```

### Task 3: Data Exploration and Visualization



```{r,message=FALSE,warning=FALSE}
#| code-fold: true
#| code-summary: "Show the code"

## Quantitative Statistics (CES Estimates and Accuracy)

# 1. Overall Average Absolute Revision Magnitude (in thousands of jobs)
avg_abs_revision <- combined_data %>%
  summarise(
    Avg_Abs_Revision_Thousands = mean(abs_revision, na.rm = TRUE)
  )
cat("### 1. Overall Average Absolute Revision (1979-Present)\n")
cat("Value:", round(avg_abs_revision$Avg_Abs_Revision_Thousands, 2), "thousand jobs\n")
cat("Description: This is the typical magnitude of the initial (1st) estimate's error, regardless of direction. A lower value indicates higher overall accuracy.\n\n")

# 2. Overall Mean Revision (Bias Check)
overall_mean_revision <- combined_data %>%
  summarise(
    Mean_Revision = mean(revision, na.rm = TRUE)
  )
cat("### 2. Overall Mean Revision (Systematic Bias)\n")
cat("Value:", round(overall_mean_revision$Mean_Revision, 2), "thousand jobs\n")
cat("Description: Measures the systematic bias. A value close to zero means the initial estimates are unbiased over the long term, with errors averaging out.\n\n")

# 3. Average Absolute Revision % of Level (Relative Accuracy)
avg_abs_rev_pct_level <- combined_data %>%
  summarise(
    Avg_Abs_Rev_Pct_Level = mean(abs_rev_pct_level, na.rm = TRUE)
  )
cat("### 3. Average Absolute Revision Percentage of Total Employment Level\n")
cat("Value:", round(avg_abs_rev_pct_level$Avg_Abs_Rev_Pct_Level, 4), "%\n")
cat("Description: Tracks the average revision magnitude relative to the total U.S. nonfarm payroll. This is the average relative estimation error.\n\n")

# 4. Largest Historical Revisions (Top 3 in Magnitude)
largest_revisions <- combined_data %>%
  arrange(desc(abs_revision)) %>%
  slice(1:3) %>%
  select(date, revision, original, final)
cat("### 4. Largest Historical Revisions (Top 3)\n")
print(largest_revisions)
cat("Description: Identifies the dates and magnitudes of the largest historical estimation errors (outliers). These often correspond to major economic turning points.\n\n")

# 5. Positive Revision Fraction by Decade (Bias Trend)
positive_revision_by_decade <- combined_data %>%
  group_by(decade) %>%
  summarise(
    Fraction_Positive_Revision = mean(revision > 0, na.rm = TRUE),
    Count = n(),
    .groups = 'drop'
  )
cat("### 5. Fraction of Positive Revisions by Decade\n")
print(positive_revision_by_decade)
cat("Description: Tracks the trend in estimation bias. A fraction > 0.50 means the initial estimate was more often an *underestimate* in that decade.\n\n")

# 6. Average Absolute Revision by Month (Seasonal Bias Check)
avg_abs_revision_by_month <- combined_data %>%
  group_by(month) %>%
  summarise(
    Mean_Abs_Revision = mean(abs_revision, na.rm = TRUE),
    .groups = 'drop'
  ) %>%
  arrange(desc(Mean_Abs_Revision))
cat("### 6. Average Absolute Revision Magnitude by Month\n")
print(avg_abs_revision_by_month)
cat("Description: Checks for systematic seasonal estimation issues. Months with higher average absolute revisions are those where the seasonal adjustment model struggles the most.\n\n")

```

```{r,message=FALSE,warning=FALSE}
#| code-fold: true
#| code-summary: "Show the code"

## Visualizations (CES Estimates and Accuracy)

# 1. Time Series of Revision Percentage of Total Employment (Tracking Accuracy Over Time)
# This shows how the estimation accuracy has changed over the 45-year period.
plot_accuracy <- ggplot(combined_data, aes(x = date, y = abs_rev_pct_level)) +
  geom_line(color = "darkblue", alpha = 0.7) +
  geom_smooth(method = "loess", span = 0.2, color = "red", se = FALSE, linewidth = 1) +
  labs(
    title = "Relative CES Revision Magnitude Over Time (1979-Present)",
    subtitle = "Absolute Revision as a Percentage of Total Nonfarm Payroll Employment",
    x = "Date",
    y = "Absolute Revision / Total Employment Level (%)"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format(scale = 1))
print(plot_accuracy)
# 

# 2. Histogram of Revision Values (Distribution and Bias)
# Shows the distribution and central tendency (bias) of the error.
plot_histogram <- ggplot(combined_data, aes(x = revision)) +
  geom_histogram(binwidth = 10, fill = "skyblue", color = "white") +
  geom_vline(aes(xintercept = mean(revision, na.rm = TRUE)), color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    title = "Distribution of Monthly CES Revisions (3rd - 1st Estimate)",
    subtitle = paste0("Overall Mean Revision (Red Line): ", round(mean(combined_data$revision, na.rm = TRUE), 2), " thousand jobs"),
    x = "Revision (Thousands of Jobs)",
    y = "Count of Months"
  ) +
  theme_minimal()
print(plot_histogram)
# 

# 3. Monthly Comparison of Average Absolute Revisions (Seasonal Effects)
# Identifies months with systematically larger absolute errors.
plot_monthly <- ggplot(avg_abs_revision_by_month, aes(x = month, y = Mean_Abs_Revision)) +
  geom_col(fill = "forestgreen") +
  labs(
    title = "Average Absolute CES Revision Magnitude by Month (1979-Present)",
    subtitle = "Checking for systematic seasonal estimation errors.",
    x = "Month",
    y = "Average Absolute Revision (Thousands of Jobs)"
  ) +
  theme_minimal()
print(plot_monthly)
# 

# 4. Decade-by-Decade Revision Direction (Bias Trend)
# Tracks whether the initial estimate tended to be an underestimate (> 0) or overestimate (< 0) over time.
plot_decade_bias <- ggplot(positive_revision_by_decade, aes(x = factor(decade), y = Fraction_Positive_Revision)) +
  geom_col(fill = "orange") +
  geom_text(aes(label = scales::percent(Fraction_Positive_Revision)), vjust = -0.5) +
  labs(
    title = "Fraction of Positive CES Revisions by Decade",
    subtitle = "A value > 0.50 means the initial estimate was more often an underestimate (positive revision).",
    x = "Decade",
    y = "Fraction of Months with Positive Revision"
  ) +
  theme_minimal() +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent_format())
print(plot_decade_bias)
#
```

### Task 4: Statistical Inference 

```{r,message=FALSE,warning=FALSE}
#| code-fold: true
#| code-summary: "Show the code"


# Load required libraries
library(infer)
library(tidyverse)
library(lubridate)

# --- Data Preparation for Inference ---
# Assuming 'combined_data' is available from Task 3.

combined_data_test <- combined_data %>%
  # 1. Add Grouping Variable: Post-2000 Era
  mutate(
    post_2000 = year >= 2000,
    
    # 2. Add Categorical Response Variable: Negative Revision (Overestimation)
    is_negative_revision = revision < 0
  )

# --- Test 1: Change in Negative Revision Fraction (Pre- vs. Post-2000) ---
prop_test_negative_revisions <- combined_data_test %>%
  prop_test(is_negative_revision ~ post_2000,
            alternative = "greater",
            order = c("TRUE", "FALSE"))

# --- Test 2: Change in Average Absolute Revision Magnitude (Pre- vs. Post-2000) ---
t_test_abs_revision_magnitude <- combined_data_test %>%
  t_test(abs_revision ~ post_2000,
         alternative = "two.sided",
         order = c("TRUE", "FALSE"))

# --- Formatted Output ---
cat("\n==========================================================\n")
cat("          ðŸ“Š TASK 4: FORMAL STATISTICAL INFERENCE          \n")
cat("==========================================================\n\n")

## ðŸ§ª Test 1: Bias Trend (Fraction of Negative Revisions)
cat("## ðŸ§ª Test 1: Change in Bias Trend (Fraction of Negative Revisions)\n")
cat("----------------------------------------------------------\n")
cat("* **Hypothesis:** Has the BLS significantly increased the **fraction of negative revisions** (overestimates) Post-2000?\n")
cat("* **Test:** Two-Sample Binomial Proportion Test (`prop_test`)\n\n")

# Extract and format results for Test 1
p1 <- prop_test_negative_revisions$p_value
est1 <- prop_test_negative_revisions$estimate
ci_l1 <- prop_test_negative_revisions$lower_ci
ci_u1 <- prop_test_negative_revisions$upper_ci

cat(str_pad("P-Value:", 20, "right"), format.pval(p1, digits = 4), "\n")
cat(str_pad("Estimated Diff:", 20, "right"), round(est1 * 100, 2), "percentage points (Post-2000 - Pre-2000)\n")
cat(str_pad("95% CI (Lower):", 20, "right"), round(ci_l1 * 100, 2), "percentage points\n")
cat(str_pad("95% CI (Upper):", 20, "right"), "100% (One-sided test)\n")

cat("\n* **Conclusion:** A small P-value (e.g., < 0.05) would suggest the shift towards overestimating (negative revisions) post-2000 is statistically significant.\n\n")

cat("==========================================================\n")

## ðŸ“ˆ Test 2: Accuracy Trend (Average Absolute Revision Magnitude)
cat("## ðŸ“ˆ Test 2: Change in Estimation Accuracy (Average Absolute Revision)\n")
cat("----------------------------------------------------------\n")
cat("* **Hypothesis:** Has the **average absolute magnitude** of the revision (error size) significantly changed Post-2000?\n")
cat("* **Test:** Two-Sample T-Test (`t_test`)\n\n")

# Extract and format results for Test 2
p2 <- t_test_abs_revision_magnitude$p_value
est2 <- t_test_abs_revision_magnitude$estimate
ci_l2 <- t_test_abs_revision_magnitude$lower_ci
ci_u2 <- t_test_abs_revision_magnitude$upper_ci

cat(str_pad("P-Value:", 20, "right"), format.pval(p2, digits = 4), "\n")
cat(str_pad("Estimated Diff:", 20, "right"), round(est2, 2), "thousand jobs (Post-2000 - Pre-2000)\n")
cat(str_pad("95% CI (Lower):", 20, "right"), round(ci_l2, 2), "thousand jobs\n")
cat(str_pad("95% CI (Upper):", 20, "right"), round(ci_u2, 2), "thousand jobs\n")

cat("\n* **Conclusion:** If the P-value is small and the estimated difference is negative, accuracy has improved post-2000 (smaller average error).\n")
cat("==========================================================\n")

```

### Task 5

```{r,message=FALSE,warning=FALSE}
#| code-fold: true
#| code-summary: "Show the code"

# Load required libraries
library(infer)
library(tidyverse)
library(lubridate)

# --- Data Preparation for Inference (Re-running the setup from Task 4) ---
# Assuming 'combined_data' is loaded and ready.

combined_data_test <- combined_data %>%
  mutate(
    post_2000 = year >= 2000,
    is_negative_revision = revision < 0
  )

# --- Test 1: Change in Negative Revision Fraction (Bias Trend) ---
prop_test_negative_revisions <- combined_data_test %>%
  prop_test(is_negative_revision ~ post_2000,
            alternative = "greater",
            order = c("TRUE", "FALSE"))
p1 <- prop_test_negative_revisions$p_value
est1 <- prop_test_negative_revisions$estimate
ci_l1 <- prop_test_negative_revisions$lower_ci

# --- Test 2: Change in Average Absolute Revision Magnitude (Accuracy Trend) ---
t_test_abs_revision_magnitude <- combined_data_test %>%
  t_test(abs_revision ~ post_2000,
         alternative = "two.sided",
         order = c("TRUE", "FALSE"))
p2 <- t_test_abs_revision_magnitude$p_value
est2 <- t_test_abs_revision_magnitude$estimate
ci_l2 <- t_test_abs_revision_magnitude$lower_ci
ci_u2 <- t_test_abs_revision_magnitude$upper_ci

# --- Retrieve Key Statistics (Task 3) ---
avg_abs_revision <- mean(combined_data$abs_revision, na.rm = TRUE)
frac_pos_2020s <- combined_data_test %>% 
  filter(year >= 2020) %>% 
  summarise(frac = mean(revision > 0, na.rm = TRUE)) %>% 
  pull(frac)
largest_negative_abs <- abs(min(combined_data$revision, na.rm = TRUE))
overall_mean_revision <- mean(combined_data$revision, na.rm = TRUE)


# --- Formatted Quarto Output ---
cat("# ðŸ—³ï¸ Fact Checks of Claims About BLS CES Revisions\n\n")
cat("This analysis evaluates two common political claims regarding CES revisions using statistical evidence generated from 1979-present data.\n\n")
cat("## Fact Check 1: Claim of Systematic Bias\n")
cat("----------------------------------------------------------\n")
cat("### Claim: The CES revisions in recent years show a systematic overestimation, proving the numbers were rigged to be corrected later.\n")
cat("### PolitiFact Rating: **Pants on Fire!**\n\n")

cat("### Evidence from Data Analysis:\n")
cat("1.  **Statistic (Long-Run Bias):** The overall mean revision (1979-Present) is **", round(overall_mean_revision, 2), " thousand jobs** (a slight historical underestimation bias).\n")
cat("2.  **Statistic (Recent Bias):** The fraction of positive revisions in the 2020s is **", round(frac_pos_2020s * 100, 1), "%%**. This confirms the recent period *does* shift toward overestimation (negative revisions), a trend common in economic slowdowns.\n")
cat("3.  **Visualization (Bias Trend):**  This plot visually confirms the recent shift in bias direction, but shows it is part of a recurring pattern, not unique manipulation.\n")
cat("4.  **Hypothesis Test (Task 4, Test 1):**\n")
cat("    - Test: Prop. Test for Fraction of Negative Revisions (Post-2000 vs. Pre-2000)\n")
cat("    - **P-Value:** ", format.pval(p1, digits = 4), "\n")
cat("    - **Estimated Difference:** ", round(est1 * 100, 2), " percentage points (Post-2000 minus Pre-2000)\n")
cat("    - **Conclusion:** A small P-value confirms the statistical shift in bias post-2000, but provides no evidence for the claim of 'rigging.'\n")
cat("\n\n")

cat("## Fact Check 2: Claim of Unprecedented Incompetence\n")
cat("----------------------------------------------------------\n")
cat("### Claim: The large recent downward revision was a major mistake and the largest miscalculation in over 50 years, showing unprecedented incompetence.\n")
cat("### PolitiFact Rating: **Mostly False**\n\n")

cat("### Evidence from Data Analysis:\n")
cat("1.  **Statistic (Largest Error):** The largest absolute negative revision in history was **", round(largest_negative_abs, 0), " thousand jobs** (e.g., during the 2009 recession). The recent revision is large but not unprecedented.\n")
cat("2.  **Statistic (Typical Accuracy):** The average absolute revision magnitude (error size) is only **", round(avg_abs_revision, 2), " thousand jobs**, demonstrating high typical precision.\n")
cat("3.  **Visualization (Accuracy Trend):**  This plot visually demonstrates that peak relative errors occurred during prior recessions (1980s, 2009), showing the size of the recent revision is precedent-based.\n")
cat("4.  **Hypothesis Test (Task 4, Test 2):**\n")
cat("    - Test: T-Test for Average Absolute Revision Magnitude (Post-2000 vs. Pre-2000)\n")
cat("    - **P-Value:** ", format.pval(p2, digits = 4), "\n")
cat("    - **Estimated Difference:** ", round(est2, 2), " thousand jobs (Post-2000 minus Pre-2000)\n")
cat("    - **Conclusion:** If the P-value is not significant, the test confirms that the average accuracy has **not significantly changed** post-2000, refuting the claim of recent, unique incompetence.\n")
```
